{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data for 4 cities: MOSCOW, BARCELONA, ANTWERP, BANGKOK\n"
     ]
    }
   ],
   "source": [
    "## Checking if raw data directory is present\n",
    "import glob\n",
    "import re\n",
    "\n",
    "BASE_FOLDER = \"./raw\"\n",
    "cities = [re.search(r\".*/([A-Z]+)\", s).group(1) for s in glob.glob(f\"{BASE_FOLDER}/*/\")]\n",
    "print(f'Found data for {len(cities)} cities: {\", \".join(cities)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.date_util import generate_date_range, weekday_parser\n",
    "from utils.h5utils import load_h5_file\n",
    "import csv\n",
    "\n",
    "def process_hourly_means_to_dataframe(city, date_range):\n",
    "    # create empty frame structure\n",
    "    frame = []\n",
    "    # Fetch map mask\n",
    "    static_map_with_mask = load_h5_file(f\"{BASE_FOLDER}/{city}/{city}_static_with_region_layer.h5\")[-1]\n",
    "    #get the region indices\n",
    "    regions_mask_values = np.unique(static_map_with_mask)\n",
    "    region_indices = {}\n",
    "    for index, region in enumerate(regions_mask_values):\n",
    "        indices = np.argwhere(static_map_with_mask == region)\n",
    "        region_indices[region] = indices\n",
    "    # fetch and process temporal data files\n",
    "    for date in date_range:\n",
    "        ## Can be used to aggregate data in pandas with groupby (where weekday is 0 (i.e. sunday))\n",
    "        weekday = weekday_parser(date)\n",
    "        \n",
    "        data = load_h5_file(f\"{BASE_FOLDER}/{city}/training/2019-04-03_{city}_8ch_aggregated.h5\")\n",
    "        \n",
    "        for hour in range(24):\n",
    "            hour_frame = data[hour]\n",
    "            ### for all channels, \n",
    "            for region_id, region in region_indices.items():\n",
    "                region_mean = 0\n",
    "                for channel in [0, 2, 4, 6]:\n",
    "                    channel_frame = hour_frame[:,:,channel].astype('float')\n",
    "                    ### calculate mean voulume of the region\n",
    "                    # Clearing all 0 values so as to ignore unavailable values.\n",
    "                    channel_frame[channel_frame == 0] = np.nan\n",
    "                    region_mean += np.nanmean(channel_frame[(region)])\n",
    "                    #print(region_mean, channel_frame[(region)].sum(), np.count_nonzero(channel_frame[(region)]))\n",
    "                    \n",
    "                    #print(channel_frame.shape, region.shape, np.count_nonzero(channel_frame), np.count_nonzero(region_mean))\n",
    "                frame.append([date, weekday, hour, region_id, region_mean])\n",
    "                ### Save zipped [date, time (hour), region_id, channel id, and mean_values to frame]\n",
    "    \n",
    "    # Save frame\n",
    "    dataframe = pd.DataFrame(frame, columns=['date', 'weekday', 'hour', 'region_id', 'region_mean_volume'])\n",
    "    dataframe.to_csv(f\"{BASE_FOLDER}/{city}/hourly_processed_means.csv\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/space/home/ameychan/ut-its-project/env/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "date_range = generate_date_range(\"2019-04-01\", \"2019-05-30\")\n",
    "date_range += generate_date_range(\"2020-04-01\", \"2020-05-30\")\n",
    "dataframe = process_hourly_means_to_dataframe(\"BARCELONA\", date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['region_mean'] = dataframe['region_mean'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moscow_dataframe = process_hourly_means_to_dataframe(\"MOSCOW\", date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moscow_dataframe.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
